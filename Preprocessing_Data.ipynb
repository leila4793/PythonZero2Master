{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__contents:__\n",
    "1. [Import Library](#Import_Library)\n",
    "2. [Data Collection](#data_collection)\n",
    "3. [Exploration and Understanding](#Exploration-and-Understanding)\n",
    "   + 3.1. [View Data Structure](#View-Data-Structure)\n",
    "   + 3.2. [Desceiptive Statistics](#Desceiptive_Statistics)\n",
    "   + 3.3. [Specify the number of rows and columns](#Specify_the_number_of_rows_and_columns)\n",
    "   + 3.4. [Specify the name of the column header](#Specify_the_name_of_the_column_header)\n",
    "   + 3.5. [Rename columns](#Rename_columns)\n",
    "   + 3.6. [Delete a column or a row](#Delete_a_column_or_a_row)\n",
    "   + 3.7. [add a column](#add_a_column)\n",
    "   + 3.8. [add a row](#add_a_row)\n",
    "4. [Handling Missing Value](#Handling_Missing_Value)\n",
    "    + 4.1. [identify missing value](#identify_missing_value)\n",
    "        * 4.1.1. [Identify the row that are completely empty](#Identify_the_row_that_are_completely_empty)\n",
    "        * 4.1.2. [imputation or removal](#imputation_or_removal)\n",
    "5. [Data Cleaning](#Data_Cleaning)\n",
    "6. [Identifying outliers](#Identifying_outliers)\n",
    "7. [Data Transformation](#Data_Transformation)\n",
    "    + 7.1. [Scaling](#Scaling)\n",
    "        - 7.1.1. [Normalization](#Normalization)\n",
    "        - 7.1.2. [Standardlization](#Standardlization)\n",
    "        - 7.1.3. [Encoding Categorical Variable](#Encoding_Categorical_Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xK9TFUoKXYm0"
   },
   "source": [
    "# 1.Import Library <a id='Import_Library'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQJjbEkfXdLw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQHJdDaRRKH8"
   },
   "source": [
    "# 2.Data Collection <a id='data_collection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikUjpKomR-m8"
   },
   "source": [
    "<font color='#808080'>\n",
    "Obtain data from reliable sources, such as datases, websites or CSV files, ... .\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#808080'>\n",
    "1) read file Or load the Data\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSrlpiURSNjd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/preprocessing data/Data.csv\")\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaT97T89ZKs4"
   },
   "source": [
    "# 3.Exploration and Understanding <a id='Exploration and Understanding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJcb9LPUZQip"
   },
   "source": [
    "## 3.1.View Data Structure <a id='View Data Structure'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.head()```: <font color='#808080'> Displays the first 5 rows of the DataFrame or the first 10 rows if ```df.head(10)``` is used. </font>s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.info()```: <font color='#808080'> Provides a concise summary of the DataFrame, including data types and non-null values. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.tail()```: <font color='#808080'> Displays the last 5 rows of the DataFrame (or the last 10 rows if `df.tail(10)` is used). </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.sample()```: <font color='#808080'> Returns a random row from the DataFrame (or a random set of 10 rows if ```df.sample(10)``` is used). </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.index```: <font color='#808080'> Returns the index (row labels) of the DataFrame. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.attrs```: <font color='#808080'> Returns a dictionary of global attributes associated with the DataFrame. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.value_counts()```: <font color='#808080'> Returns the counts of unique values in a Series or DataFrame column, sorted in descending order. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df[\"feature\"].value_counts().idxmax()```: <font color='#808080'> Returns the most frequent value (mode) in the \"feature\" column.\n",
    "- ``` df[\"feature\"].value_counts().max() ```: <font color='#808080'>Returns the highest frequency (count) of the most frequent value in the \"feature\" column.\n",
    "- ```df[\"feature\"].value_counts().idxmin() ```: <font color='#808080'>Returns the least frequent value in the \"feature\" column.\n",
    "- ``` df[\"feature\"].value_counts().min()```: <font color='#808080'>Returns the lowest frequency (count) of the least frequent value in the \"feature\" column.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature name\"].value_counts().idxmax()\n",
    "df[\"feature name\"].value_counts().max()\n",
    "df[\"feature name\"].value_counts().idxmin()\n",
    "df[\"feature name\"].value_counts().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.values```: <font color='#808080'>Returns the DataFrame's data as a NumPy array, excluding the index and column labels.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.dtypes```: <font color='#808080'>Returns a Series with the data types of each column in the DataFrame.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.axes```: <font color='#808080'>Returns a list containing the row and column index objects of the DataFrame, providing the structure of its axes.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.empty```: <font color='#808080'>Returns a boolean value indicating whether the DataFrame is empty (i.e., has no rows).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.nunique()```: <font color='#808080'>Returns the count of unique values for each column in the DataFrame.\n",
    "- ```df[\"column_name\"].nunique()``` <font color='#808080'>Returns the count of unique values in the specified column (column_name) of the DataFrame) </font>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()\n",
    "df[\"column_name\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU63UR-UaJOr"
   },
   "source": [
    "## 3.2.Desceiptive Statistics <a id='Desceiptive_Statistics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.describe()```: <font color='#808080'>Generates descriptive statistics for the DataFrame.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df[\"column_name\"].mean()```: <font color='#808080'>Returns the average (mean) of the values in the specified column (column_name).</font>\n",
    "- ``` df[\"column_name\"].mode()```: <font color='#808080'>Returns a Series containing the mode(s) of the specified column (column_name). If there are multiple modes, all of them will be returned.\n",
    "- ```df[\"column_name\"].median()```: <font color='#808080'>Returns the median (the middle value) of the specified column (column_name).\n",
    "- ```df[\"column_name\"].std()```: <font color='#808080'>Returns the standard deviation of the values in the specified column (column_name), measuring the dispersion of the data points.\n",
    "- ```df[\"column_name\"].var()```: <font color='#808080'>Returns the variance of the values in the specified column (column_name), indicating the degree of spread in the data set.\n",
    "- ```df[\"column_name\"].min()```: <font color='#808080'>Returns the smallest value in the specified column (column_name).\n",
    "- ```df[\"column_name\"].max()```: <font color='#808080'>Returns the largest value in the specified column (column_name).\n",
    "- ```df[\"column_name\"].quantile(q)```: <font color='#808080'>Returns the value at the given quantile ```(e.g., q=0.5 for the median)``` for the specified column (column_name)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xDA7jqhby9F"
   },
   "source": [
    "## 3.3.Specify the number of rows and columns <a id='Specify_the_number_of_rows_and_columns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.shape```: <font color='#808080'>Returns the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XX5PuO4Icz2u"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUqQASh-c1dI"
   },
   "source": [
    "## 3.4.Specify the name of the column header <a id='Specify_the_name_of_the_column_header'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.column```: <font color='#808080'>Returns all Header names of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-XIB8xrfT8F"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM0_UJW9fVbx"
   },
   "source": [
    "## 3.5.Rename columns <a id='Rename_columns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.rename(columns={'Age': 'age'}, inplace=False)```: <font color='#808080'> Returns a new DataFrame with the specified columns renamed```((in this case changing'Ag' to'ag)```), without modifying the original DataFrame since`` `inplace=Fals``e` is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FSHWFfigclx"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Age': 'age'}, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljcDL_DugqdO"
   },
   "source": [
    "## 3.6.Delete a column or a row <a id='Delete_a_column_or_a_row'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df = df.drop(\"Age\", axis=1)```: <font color='#808080'>  Removes the column labele \"Ag\" from the DataFram  wit axis = 1, ` indicating that a column is being dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sWxTfmchQya"
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"Age\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df = df.drop(0, axis=0)```: <font color='#808080'> Removes the row with the index label 0 from the DataFrame, with axis=0 indicating that a row is being dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gf0BNHfthUGb"
   },
   "outputs": [],
   "source": [
    "df = df.drop(0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3xJywSci0fb"
   },
   "source": [
    "## 3.7.add a column <a id='add_a_column'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df[\"M\"] = 10```: <font color='#808080'>Creates a new column named \"M\" in the DataFrame and assigns the value 10 to all rows in that column.\n",
    "- ```df[\"M\"] = np.nan```: <font color='#808080'>Creates a new column named \"M\" in the DataFrame and assigns NaN (Not a Number) to all rows in that column, effectively indicating missing or undefined values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"M\"] = 10\n",
    "df[\"M\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df[\"upper_name\"] = df['Country'].apply(lambda x : x.upper())```: <font color='#808080'>Creates a new column named \"upper_name\" in the DataFrame by applying a lambda function that converts the values in the \"Country\" column to uppercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"upper_name\"] = df['Country'].apply(lambda x : x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df[\"new_column\"] = [0,1,2,0,0,0,1,1,0]```: <font color='#808080'> Creates a new column named \"new_column\" in the DataFrame and assigns the provided list of values [0, 1, 2, 0, 0, 0, 1, 1, 0] to it. The length of the list must match the number of rows in the DataFrame; otherwise, it will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_column\"] = [0,1,2,0,0,0,1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt39TWGvlBWV"
   },
   "source": [
    "## 3.8.add a row <a id='add_a_row'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#808080'> **adding a new row  using loc[]:**\n",
    "\n",
    "**<font color='#808080'>these methods only allows adding column to the beginning or end of the DataFrame**\n",
    "- ```df.loc[len(df)] = [\"Iran\", 54.0, 52000, \"Yes\"]```: <font color='#808080'>Adds a new row at the end of the DataFrame with the specified values, using the current length of the DataFrame as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df)] = [\"Iran\", 54.0, 52000, \"Yes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.loc[5:] = [\"Iran\", 54.0, 52000, \"Yes\"]```: <font color='#808080'>Attempts to assign the specified values to all rows from index 5 to the end of the DataFrame, which can result in an error if the indices do not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[5:] = [\"Iran\", 54.0, 52000, \"Yes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df.loc[:] = [\"Iran\", 54.0, 52000, \"Yes\"]```: <font color='#808080'> Attempts to replace all rows in the DataFrame with the specified values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:] = [\"Iran\", 54.0, 52000, \"Yes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>adding a new row with using concat()**\n",
    "- ``` new_data = pd.DataFrame({\"Country\": [\"Dubai\"], \"Age\": [39.0], \"Salary\": [96000.0], \"Purchased\": [\"Yes\"]}):```: Creates a new DataFrame named new_data with one row of data.\n",
    "- ```df = pd.concat([df, new_data], ignore_index=True)```: <font color='#808080'> Concatenates new_data to the original DataFrame df, resetting the index with ignore_index=True to maintain sequential indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\"Country\":[\"Dubai\"],\t\"Age\":[39.0], \"Salary\":[96000.0],\t\"Purchased\":[\"Yes\"]})\n",
    "df = pd.concat([df, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```new_data = pd.DataFrame({\"Country\":[\"Usa\"],\"Age\":[45.0],\"Salary\":[10000.2],\"Purchased\":[\"No\"]})```: <font color='#808080'> Creates another DataFrame named new_data with one row of data.\n",
    "- ```df = df._append(new_data, ignore_index=True)```: <font color='#808080'> Appends new_data to the DataFrame df, similar to concat(), but with an emphasis on the append function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\"Country\":[\"Usa\"],\"Age\":[45.0],\"Salary\":[10000.2],\"Purchased\":[\"No\"]})\n",
    "df = df._append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```new_row = pd.Series([np.nan]*len(df.columns), index=df.columns)```: <font color='#808080'>Creates a new Series filled with NaN values, matching the number of columns in the DataFrame.\n",
    "- ``` df = df._append(new_row, ignore_index=True)```: <font color='#808080'> Appends the new row filled with NaN to the DataFrame df, effectively adding a row with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.Series([np.nan]*len(df.columns), index=df.columns)\n",
    "df = df._append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HbF08oHrLDp"
   },
   "source": [
    "# 4.Handling Missing Value <a id='Handling_Missing_Value'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFTtgv-34o5e"
   },
   "source": [
    "## 4.1.identify missing value <a id='identify_missing_value'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Identifying Missing Values in Rows**\n",
    "- ```df.isna().sum(axis=1)```: <font color='#808080'>Returns a Series containing the count of missing values (NaN) for each row in the DataFrame. axis=1 indicates that the operation is performed across columns.\n",
    "- ```df.isnull().sum(axis=1)```: <font color='#808080'>Functions similarly to isna(), returning a Series with the count of missing values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum(axis=1)\n",
    "df.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Identifying Missing Values in Columns**\n",
    "- ```df.isna().sum(axis=0)```:<font color='#808080'>Returns a Series containing the count of missing values (NaN) for each column in the DataFrame. axis=0 indicates that the operation is performed across rows.\n",
    "- ```df.isnull().sum(axis=0)```:<font color='#808080'>Functions similarly to isna(), returning a Series with the count of missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAd8jMvV4_Bg"
   },
   "outputs": [],
   "source": [
    "df.isna().sum(axis=0)\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujm7yNqL5mkq"
   },
   "source": [
    "### 4.1.1.Identify the row that are completely empty <a id='Identify_the_row_that_are_completely_empty'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Identify the Number of Completely Empty Rows**\n",
    "- ```df.isna().all(axis=1).sum()```:<font color='#808080'>Returns the count of rows that are completely empty (i.e., all values are NaN) by checking each row with isna(), using all(axis=1) to ensure all values in the row are NaN, and then summing the resulting boolean values.\n",
    "- ```df.isnull().all(axis=1).sum()```:<font color='#808080'> Functions similarly to the above method, returning the count of completely empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().all(axis=1).sum()\n",
    "df.isnull().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Show Indices of Completely Empty Rows**\n",
    "- ```df.index[df.isna().all(axis=1)].tolist()```:<font color='#808080'>Returns a list of the indices of rows that are completely empty (all values are NaN). The condition checks each row for completeness, and the resulting indices are converted to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlBSaVh36u_-"
   },
   "outputs": [],
   "source": [
    "df.index[df.isna().all(axis=1)].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrfexKLF6_fH"
   },
   "source": [
    "### 4.1.2.imputation or removal <a id='imputation_or_removal'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Deleting Rows that are Completely Empty**\n",
    "- ```df.dropna(how=\"all\")```:<font color='#808080'>Removes all rows from the DataFrame that are completely empty (i.e., all values are NaN). The how=\"all\" parameter specifies that a row should be dropped only if all its values are NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Filling NaN Values in a Column**\n",
    "- ```df[\"Purchased\"] = df[\"Purchased\"].fillna(\"No\")```:<font color='#808080'>Fills any NaN values in the \"Purchased\" column with the string \"No\". This replaces missing values with a specified default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Purchased\"] = df[\"Purchased\"].fillna(\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Filling NaN Values with Mean, Mode, or Median**\n",
    "- ```df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())```:<font color='#808080'> Replaces NaN values in the \"Age\" column with the mean of that column. Similar methods can be applied using .mode() or .median() for replacing with the mode or median, respectively:\n",
    "*Mode:* ```df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mode()[0])```\n",
    "\n",
    "*Median:* ```df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWh4nk477je4"
   },
   "outputs": [],
   "source": [
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mode()[0])\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8gnLLjj7oOf"
   },
   "source": [
    "# 5.Data Cleaning <a id='Data_Cleaning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Identifying Duplicated Rows**\n",
    "- ```df.duplicated().sum()```:<font color='#808080'>Returns the count of duplicated rows in the DataFrame. This method marks rows as duplicated if they are identical to a previous row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Showing Duplicated Rows**\n",
    "- ```df.index[df.duplicated(keep=False)].tolist()```:<font color='#808080'> Returns a list of the indices of all duplicated rows. The keep=False parameter indicates that all occurrences of duplicated rows should be included, not just the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[df.duplicated(keep=False)].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Removing Duplicated Rows**\n",
    "- ```df.drop_duplicates()```:<font color='#808080'> Removes duplicated rows from the DataFrame, keeping the first occurrence by default. This method returns a new DataFrame without the duplicates, while the original DataFrame remains unchanged unless assigned back to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xnw_fRCQBbm_"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDVkGgSAC60v"
   },
   "source": [
    "# 6.Identifying outliers <a id='Identifying_outliers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'> Using Z-score for Normal Distribution:**\n",
    "- ```z_score = stats.zscore(df[\"Age\"])```: <font color='#808080'> Calculates the Z-scores for the \"Age\" column, which measures how many standard deviations each value is from the mean. This is useful for identifying outliers in a normally distributed dataset.\n",
    "- ```outliners = df[(z_score > 3) | (z_score < -3)]```: <font color='#808080'>Identifies the outliers based on the Z-scores. Rows where the absolute value of the Z-score is greater than 3 are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = stats.zscore(df[\"Age\"])\n",
    "outliners = df[(z_score > 3) | (z_score <-3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Using IQR for Abnormal Distribution**\n",
    "- ```q1 = df[\"Age\"].quantile(0.25)```:<font color='#808080'> Calculates the first quartile (25th percentile) of the \"Age\" column.\n",
    "- ```q3 = df[\"Age\"].quantile(0.75)```:<font color='#808080'> Calculates the third quartile (75th percentile) of the \"Age\" column.\n",
    "- ```IQR = q3 - q1```:<font color='#808080'>Computes the Interquartile Range (IQR), which is the difference between the third and first quartiles.\n",
    "- ```outliners = df[(df[\"Age\"] < (q1 - 1.5 * IQR)) | (df[\"Age\"] > (q3 + 1.5 * IQR))]```: <font color='#808080'>Identifies outliers using the IQR method. Values below ```𝑞1 − 1.5 × 𝐼𝑄𝑅``` or above ```q3 + 1.5 × IQR``` are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df[\"Age\"].quantile(0.25)\n",
    "q3 = df[\"Age\"].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "outliners = df[(df[\"Age\"] < (q1 - 1.5 * IQR)) | (df[\"Age\"] > (q3 + 1.5 * IQR))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Using Boxplot**\n",
    "- ```sns.boxplot(x=df[\"Age\"])```:Creates a boxplot for the \"Age\" column using Seaborn, visually representing the distribution, median, quartiles, and potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=df[\"Age\"])\n",
    "plt.title(\"Boxplot for age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ecm3ylBKrbO"
   },
   "source": [
    "# 7.Data Transformation <a id='Data_Transformation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Identifying a Column with Two Formats**\n",
    "- ```df_string = df[\"Age\"].apply(lambda x : isinstance(x, str))```: <font color='#808080'> Checks each value in the \"Age\" column to determine if it is a string. The result is a Series of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string = df[\"Age\"].apply(lambda x : isinstance(x, str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Deleting Noise**\n",
    "- ```pd.to_numeric(df[\"Age\"], errors=\"coerce\")```:<font color='#808080'>Converts the \"Age\" column to numeric values. Any values that cannot be converted (e.g., strings or non-numeric entries) are replaced with NaN due to the errors=\"coerce\" parameter, effectively cleaning the column of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(df[\"Age\"],  errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Converting the Data Type of a Column**\n",
    "- ```df[\"Age\"] = df[\"Age\"].astype(str)```: <font color='#808080'>Converts the \"Age\" column to string data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiQ1UMvRKvrm"
   },
   "outputs": [],
   "source": [
    "df[\"Age\"] = df[\"Age\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruWYX3NUhGbh"
   },
   "source": [
    "## 7.1.**Scaling**  <a id='Scaling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocmU16BxOCQW"
   },
   "source": [
    "### 7.1.1. **Normalization** <a id='Normalization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#808080'>the descriptions for the different data scaling methods mentioned, including the context of scaling data to a specific range (0 to 1):\n",
    "\n",
    "**<font color='#808080'>Min-Max Scaling**\n",
    "- ```scaler = MinMaxScaler()```: <font color='#808080'> Initializes the MinMaxScaler.\n",
    "- ```scaler.fit_transform(data)```: <font color='#808080'>Fits the scaler to the data and transforms it, scaling each feature to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Max Abs Scaling** Scales each feature by dividing by its maximum absolute value, preserving the sign and resulting in values in the range [-1, 1].\n",
    "\n",
    "- ```max_abs_scaler = MaxAbsScaler()```: <font color='#808080'> Initializes an instance of the MaxAbsScaler to scale features by their maximum absolute value.\n",
    "- ```scaled_data = max_abs_scaler.fit_transform(data)```: <font color='#808080'> Fits the scaler to the data and transforms it, scaling each feature to the range [-1, 1] based on its maximum absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "scaled_data = max_abs_scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'> Logarithm scaling** Transforms data by applying the natural logarithm, useful for reducing skewness and managing exponential growth, especially with positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9iczTW0dPz4"
   },
   "outputs": [],
   "source": [
    "# z-score NOrmalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Yb7rHcsdq5T"
   },
   "source": [
    "### 7.1.2.**Standardlization** <a id='Standardlization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#808080'>Standardization of data means scaling the data so that the mean of the data is equal to zero and the standard deviation is equal to one. \n",
    "\n",
    "**<font color='#808080'>Advantages:**\n",
    "\n",
    "+ <font color='#808080'> Applicable in sensitive models like logistic regression, SVM, and KNN that are sensitive to the scale of the data.\n",
    "+ <font color='#808080'> It is excellent for data that approximately follows a normal distribution.\n",
    "+ <font color='#808080'> In algorithms like gradient descent, standardizing the data accelerates the learning process.\n",
    "\n",
    "- ```scaler = StandardScaler()```:<font color='#808080'> Initializes an instance of the StandardScaler, which standardizes features by removing the mean and scaling to unit variance.\n",
    "- ```scaler.fit_transform(data)```:<font color='#808080'> Fits the scaler to the provided data and transforms it, resulting in a dataset with a mean of 0 and a standard deviation of 1 for each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcCzwE2kdwWZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'> In cases where we have outliers, we should use the following.**\n",
    "- ```scaler = RobustScaler()```:Initializes an instance of the `RobustScaler`, which scales features using statistics that are robust to outliers, specifically the median and the interquartile range (IQR), making it suitable for datasets with extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0poM-tNi9aB"
   },
   "source": [
    "### 7.1.3.**Encoding Categorical Variable** <a id='Encoding_Categorical_Variable'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>One-Hot Encoding**A common method for converting categorical data into a numerical format, creating binary columns for each category. \n",
    "* <font color='#808080'> _with Pandas_:\n",
    "- ```pd.get_dummies(df, columns=[\",,,,\"])```:<font color='#808080'> generate one-hot encoded columns directly from a DataFrame.\n",
    "* <font color='#808080'> _with sklearn_:\n",
    "- ```encoder = OneHotEncoder(sparse=False)```:<font color='#808080'> initialize OneHotEncoder, and use ```encoder.fit_transform(df[...])``` to encode the specified categorical features.\n",
    "- ```encoder.get_feature_names_out([...])```: <font color='#808080'>Create a DataFrame from the encoded data and set the column names and Display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df, columns=[\",,,,\"])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "encoded_data = encoder.fit_transform(df[\",,,\"])\n",
    "encoder.get_feature_names_out([\",,,\"])\n",
    "pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out[\",,,\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Label Encoding** Converts categorical data into numerical format by assigning a unique integer to each category.\n",
    "Implemented using ```LabelEncoder``` from ```sklearn.preprocessing```, where ```encoder.fit_transform(df[...])``` converts the specified categorical feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit_transform(df[\",,\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='#808080'>Discretization** The process of converting continuous data into discrete categories or bins.\n",
    "\n",
    "+ <font color='#808080'> _with Pandas_:\n",
    "\n",
    "<font color='#808080'> Use ```pd.cut(df[...], bins=..., labels=[])``` to define bins for the continuous variable and assign labels.\n",
    "+ <font color='#808080'> _Scikit-learn_:\n",
    "\n",
    "Import ```KBinsDiscretizer from sklearn.preprocessing```, configure it with the desired number of bins and encoding type, and use it to transform the continuous feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikyMyzCajGYI"
   },
   "outputs": [],
   "source": [
    "#first way with pandas\n",
    "pd.cut(df[\",,,\"], bins= , labels=[])\n",
    "\n",
    "#second way with sklearn\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "KBinsDiscretizer(n_bins=  , encode= \"ordinal\", strategy=\"uniform\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO53/EICWFwvn3tbi/k2erW",
   "collapsed_sections": [
    "xK9TFUoKXYm0",
    "kQHJdDaRRKH8",
    "ikUjpKomR-m8",
    "jaT97T89ZKs4",
    "VJcb9LPUZQip",
    "TU63UR-UaJOr",
    "0xDA7jqhby9F",
    "RUqQASh-c1dI",
    "pM0_UJW9fVbx",
    "ljcDL_DugqdO",
    "j3xJywSci0fb",
    "lt39TWGvlBWV",
    "9HbF08oHrLDp",
    "nFTtgv-34o5e",
    "ujm7yNqL5mkq",
    "WrfexKLF6_fH",
    "C8gnLLjj7oOf",
    "eDVkGgSAC60v",
    "2Ecm3ylBKrbO"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
